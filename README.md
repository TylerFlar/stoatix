# Stoatix

A lightweight CLI tool for system benchmarking and diagnostics.

## Quickstart

```bash
# Clone the repository
git clone https://github.com/TylerFlar/stoatix.git
cd stoatix

# Install dependencies
uv sync

# Validate a configuration file
uv run stoatix validate examples/stoatix.yaml

# Dry run (validate + write metadata without executing)
uv run stoatix run examples/stoatix.yaml --dry-run

# Run benchmarks
uv run stoatix run examples/stoatix.yaml --out out/

# Run with shuffle (randomized case order)
uv run stoatix run examples/stoatix.yaml --shuffle --seed 12345

# Run with Linux perf stat counters (Linux only)
uv run stoatix run examples/stoatix.yaml --perf-stat
```

## Results

After running benchmarks, results are written to the output directory:

- **`out/session.json`** â€” Metadata about the run including suite ID, config hash, system info, and git info
- **`out/config.resolved.yml`** â€” Resolved configuration with all defaults expanded
- **`out/cases.json`** â€” Expanded cases in execution order
- **`out/results.jsonl`** â€” One JSON record per benchmark attempt with timing data
- **`out/summary.csv`** â€” Aggregated statistics per case (generated by default)

## Summary Statistics

By default, `stoatix run` generates `summary.csv` with per-case statistics.

### Record Selection

- **Only `measured` runs** are included (warmups are excluded)
- **Retry handling**: For each (case_id, iteration), the **first successful attempt** (`ok=true`) is used. If all attempts failed, that iteration is counted as failed and excluded from timing stats.

### Outlier Filtering

| Method | Description |
|--------|-------------|
| `iqr` (default) | Per-case IQR filtering: values outside [Q1 - 1.5Ã—IQR, Q3 + 1.5Ã—IQR] are dropped |
| `none` | Keep all successful elapsed times |

Use `--outliers none` or `--outliers iqr` to control this behavior.

### Statistics Definitions

| Statistic | Definition |
|-----------|------------|
| `median_s` | Median of filtered elapsed times |
| `mean_s` | Arithmetic mean of filtered elapsed times |
| `stdev_s` | Sample standard deviation (ddof=1); blank if n < 2 |
| `p95_s` | 95th percentile using linear interpolation between adjacent sorted values |
| `min_s`, `max_s` | Min/max of filtered elapsed times |

### Standalone Summarization

```bash
# Summarize existing results
uv run stoatix summarize out/results.jsonl

# Specify output path and outlier method
uv run stoatix summarize out/results.jsonl --out report.csv --outliers none
```

## Configuration

Create a YAML file with your benchmarks:

```yaml
# Optional defaults applied to all benchmarks
defaults:
  warmups: 2
  runs: 5
  retries: 0
  timeout_s: 60.0
  env:
    MY_VAR: "value"

benchmarks:
  - name: my-benchmark
    command: ["python", "-c", "print('hello')"]
    warmups: 1      # warmup iterations (not measured)
    runs: 5         # measured iterations
    timeout_s: 10.0 # optional timeout in seconds

  # Matrix expansion example
  - name: parameterized-bench
    command: ["python", "-c", "print({n})"]
    matrix:
      n: [100, 1000, 10000]
```

The `command` must be a list of strings (exec form, no shell).

## CLI Reference

```bash
# Show help
uv run stoatix --help

# Show version
uv run stoatix --version

# Validate config without running
uv run stoatix validate <config.yaml>

# Run benchmarks
uv run stoatix run <config.yaml> [OPTIONS]

# Run command options:
#   --out, -o PATH       Output directory (default: out)
#   --shuffle            Shuffle case execution order
#   --no-shuffle         Preserve deterministic order (default)
#   --seed INTEGER       Random seed for shuffling
#   --dry-run            Write metadata files without executing benchmarks
#   --summarize          Generate summary.csv after run (default)
#   --no-summarize       Skip summary generation
#   --outliers TEXT      Outlier filtering: 'iqr' (default) or 'none'
#   --perf-stat          Collect Linux perf stat counters (Linux only)
#   --perf-events TEXT   Comma-separated perf events (has sensible defaults)
#   --perf-strict        Fail if perf unavailable (default: degrade gracefully)

# Summarize existing results
uv run stoatix summarize <results.jsonl> [OPTIONS]

# Summarize command options:
#   --out, -o PATH       Output CSV path (default: summary.csv in same dir)
#   --outliers TEXT      Outlier filtering: 'iqr' (default) or 'none'

# Compare two result files (e.g., main vs PR)
uv run stoatix compare <main.jsonl> <pr.jsonl> [OPTIONS]

# Compare command options:
#   --threshold FLOAT      Classification threshold (default: 0.05)
#   --metric TEXT          median_s | mean_s | p95_s (default: median_s)
#   --sort TEXT            stable | priority (default: priority)
#   --top INTEGER          Max rows in markdown table (default: 50)
#   --json-out PATH        Output JSON path (default: compare.json next to pr)
#   --md-out PATH          Optional markdown output file

# Profile cases with perf record (Linux only)
uv run stoatix profile <config.yaml|cases.json> [OPTIONS]

# Profile command options:
#   --out, -o PATH         Output directory (default: out)
#   --case-id TEXT         Case ID(s) to profile (repeatable)
#   --bench TEXT           Filter by benchmark name substring
#   --case-key-contains    Filter by case_key substring
#   --from-compare PATH    Select top regressions from compare.json
#   --top INTEGER          Number of regressions to profile (default: 5)
#   --freq INTEGER         Sampling frequency in Hz (default: 99)
#   --call-graph TEXT      fp | dwarf (default: dwarf)
#   --flamegraph-dir PATH  Directory containing FlameGraph scripts
#   --strict/--no-strict   Fail on errors vs degrade gracefully (default: strict)

# Examples:
uv run stoatix run config.yaml --out results/
uv run stoatix run config.yaml --shuffle --seed 42
uv run stoatix run config.yaml --no-summarize
uv run stoatix run config.yaml --outliers none
uv run stoatix summarize out/results.jsonl --out report.csv
uv run stoatix compare main/results.jsonl pr/results.jsonl --threshold 0.03
uv run stoatix profile config.yaml --case-id abc123 --out profiles/
uv run stoatix profile out/cases.json --from-compare out/compare.json --top 3
```

## Linux perf stat Integration

On Linux, Stoatix can collect hardware performance counters via `perf stat`:

```bash
# Enable perf stat collection
uv run stoatix run config.yaml --perf-stat

# Custom events (default includes cycles, instructions, cache misses, etc.)
uv run stoatix run config.yaml --perf-stat --perf-events "cycles,instructions,LLC-loads,LLC-load-misses"

# Strict mode: fail if perf is unavailable
uv run stoatix run config.yaml --perf-stat --perf-strict
```

**Requirements:**
- Linux with `perf` installed (`linux-tools-generic` on Ubuntu/Debian)
- Appropriate permissions (may need `sudo` or `kernel.perf_event_paranoid` sysctl)

**Behavior:**
- `--perf-stat`: Wraps each command with `perf stat -e <events> -x, --`
- Counters are stored in `perf_counters` field of each result record
- Without `--perf-strict`: gracefully degrades to timing-only if perf unavailable
- With `--perf-strict`: exits with error if perf cannot collect data

## Comparing Results

The `compare` command detects regressions between two benchmark runs (e.g., main branch vs PR).

### Input

Both arguments must be `results.jsonl` files from `stoatix run`. Cases are matched by `(bench_name, case_id)`.

### Classification

Percent change is computed as:

```
pct_change = (pr_metric - main_metric) / main_metric
```

| Classification | Condition |
|----------------|-----------|
| **regressed** | `pct_change > threshold` |
| **improved** | `pct_change < -threshold` |
| **unchanged** | within Â±threshold |
| **added** | case exists only in PR |
| **removed** | case exists only in main |

Default threshold is 5% (`--threshold 0.05`). Default metric is `median_s`.

### Needs Attention

Cases are flagged when results may be unreliable:

- **High CV**: `stdev_s / median_s >= 0.05` (coefficient of variation)
- **Long tail**: `p95_s / median_s >= 1.10`
- **Low samples**: fewer than 3 OK iterations in either run

Tune with `--noise-cv`, `--noise-p95-ratio`, `--min-ok`.

### Determinism

Output is fully deterministic for reproducible CI:

- **Stable sort** (`--sort stable`): rows ordered by `(bench_name, case_key, case_id)`
- **Priority sort** (`--sort priority`, default): regressed cases first, then stable order within each classification

Upstream run ordering can be randomized with `stoatix run --shuffle --seed <N>` to reduce measurement bias, but comparison results remain deterministic regardless of execution order.

## Deep Profiling

The `profile` command captures detailed CPU profiles with `perf record` and generates interactive flamegraphs.

### Usage

```bash
# Profile specific cases from config
uv run stoatix profile stoatix.yml --out out/ --case-id abc123 --case-id def456

# Profile top 3 regressions from a compare result
uv run stoatix profile out/cases.json --from-compare out/compare.json --top 3

# Filter by benchmark name or case key
uv run stoatix profile stoatix.yml --bench "sort" --case-key-contains "n=1000"
```

### Requirements

- **Linux** with `perf` installed (`linux-tools-generic` on Ubuntu/Debian)
- **FlameGraph tools** for SVG generation:
  - `stackcollapse-perf.pl` and `flamegraph.pl` on PATH, OR
  - `--flamegraph-dir /path/to/FlameGraph/` pointing to the [FlameGraph repo](https://github.com/brendangregg/FlameGraph)

### Output

Profiles are written to `out/profiles/<case_id>/`:

| File | Description |
|------|-------------|
| `perf.data` | Raw perf record data |
| `perf.script` | Decoded stack traces |
| `folded.txt` | Collapsed stacks for flamegraph |
| `flamegraph.svg` | Interactive flamegraph (if tools available) |
| `meta.json` | Audit link: case definition, perf version, timestamps |

### Options

```bash
# Perf sampling options
--freq 99              # Sampling frequency in Hz (default: 99)
--call-graph dwarf     # Call graph method: 'fp' or 'dwarf' (default: dwarf)

# Strict mode (default)
--strict               # Fail if perf missing or flamegraph generation fails

# Non-strict mode
--no-strict            # Capture what's possible, warn on failures
```

### Integration with Reports

When `out/profiles/` exists, `stoatix report` automatically:
- Adds a **Profile** column with ðŸ”¥ links in the results table
- Includes a **Profiles** section listing all flamegraphs and metadata files

## License

MIT
